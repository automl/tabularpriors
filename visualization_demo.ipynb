{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67fa7b2",
   "metadata": {},
   "source": [
    "# TabularPriors Visualization and Demo Notebook\n",
    "\n",
    "This notebook shows how to generate, load, and visualize synthetic tabular data using the `tabularpriors` package. Youâ€™ll see examples for both regression and classification, using different types of priors, with clear visualizations to help you explore the data.\n",
    "\n",
    "## Contents:\n",
    "\n",
    "1. **TICL MLP Prior Regression** - Visualizing regression data generated from MLP priors\n",
    "2. **TICL GP Prior Regression** - Visualizing regression data from Gaussian Process priors\n",
    "3. **TabICL Classification** - Visualizing classification data from TabICL priors\n",
    "4. **Live Data Generation** - Generating and visualizing synthetic data in real-time\n",
    "\n",
    "## Prerequisites:\n",
    "\n",
    "- Ensure you have the tabularpriors package installed\n",
    "- Run the necessary commands to generate the HDF5 data files as shown in each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tabularpriors.dataloader import PriorDumpDataLoader\n",
    "\n",
    "def plot_regression_samples(X_data, y_data, title, color, batch_size=20):\n",
    "    \"\"\"Plot regression feature-target and sample evolution.\"\"\"\n",
    "    num_features = X_data.shape[2]\n",
    "    if num_features == 1:\n",
    "        _plot_regression_1d(X_data, y_data, title, batch_size)\n",
    "    elif num_features >= 2:\n",
    "        _plot_regression_simplified(X_data, y_data, title, color, batch_size, num_features)\n",
    "\n",
    "def _plot_regression_1d(X_data, y_data, title, batch_size):\n",
    "    \"\"\"Plot 1D regression samples.\"\"\"\n",
    "    rows, cols = 4, 5\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 12))\n",
    "    axes = axes.flatten()\n",
    "    for i in range(batch_size):\n",
    "        X_i = X_data[i, :, 0]\n",
    "        y_i = y_data[i, :]\n",
    "        axes[i].scatter(X_i, y_i, color='blue', alpha=0.7, s=20)\n",
    "        axes[i].set_title(f\"Sample {i + 1}\")\n",
    "        axes[i].set_xlabel(\"x\")\n",
    "        axes[i].set_ylabel(\"y\")\n",
    "    for i in range(batch_size, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _plot_regression_simplified(X_data, y_data, title, color, batch_size, num_features):\n",
    "    \"\"\"Plot multi-feature regression stats and plots.\"\"\"\n",
    "    # Print stats first\n",
    "    _print_regression_statistics(X_data, y_data, num_features, batch_size)\n",
    "    # Feature vs Target plots\n",
    "    fig1 = plt.figure(figsize=(15, 5))\n",
    "    for feat_idx in range(min(3, num_features)):\n",
    "        ax = plt.subplot(1, 3, feat_idx + 1)\n",
    "        _plot_feature_vs_target(X_data, y_data, feat_idx, ax, color, f\"Feature {feat_idx + 1}\")\n",
    "    plt.suptitle(f\"{title} - Feature-Target Relationships\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Sample Evolution Analysis\n",
    "    fig2 = plt.figure(figsize=(16, 10))\n",
    "    for sample_idx in range(min(4, batch_size)):\n",
    "        ax = plt.subplot(2, 2, sample_idx + 1)\n",
    "        _plot_single_sample_analysis(X_data, y_data, sample_idx, ax, color, num_features)\n",
    "    plt.suptitle(f\"{title} - Sample Evolution Analysis\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _plot_feature_vs_target(X_data, y_data, feature_idx, ax, color, label):\n",
    "    \"\"\"Plot feature vs target.\"\"\"\n",
    "    all_x = X_data[:, :, feature_idx].flatten()\n",
    "    all_y = y_data.flatten()\n",
    "    ax.scatter(all_x, all_y, color=color, alpha=0.4, s=12)\n",
    "    ax.set_xlabel(label, fontsize=12)\n",
    "    ax.set_ylabel('Target', fontsize=12)\n",
    "    ax.set_title(f'{label} vs Target', fontsize=12, pad=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    correlation = np.corrcoef(all_x, all_y)[0, 1]\n",
    "    ax.text(0.05, 0.95, f'r = {correlation:.3f}', transform=ax.transAxes, \n",
    "           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
    "           fontsize=10, verticalalignment='top')\n",
    "\n",
    "def _plot_single_sample_analysis(X_data, y_data, sample_idx, ax, color, num_features):\n",
    "    \"\"\"Plot single sample evolution.\"\"\"\n",
    "    if num_features == 1:\n",
    "        x = X_data[sample_idx, :, 0]\n",
    "        y = y_data[sample_idx, :]\n",
    "        ax.plot(x, y, 'o-', color='blue', alpha=0.7, markersize=4)\n",
    "        ax.set_xlabel('Feature 1', fontsize=11)\n",
    "        ax.set_ylabel('Target', fontsize=11)\n",
    "    else:\n",
    "        seq_len = X_data.shape[1]\n",
    "        x_axis = np.arange(seq_len)\n",
    "        feature_colors = ['#1f77b4', '#9467bd', '#2ca02c']\n",
    "        for feat_idx in range(min(3, num_features)):\n",
    "            ax.plot(x_axis, X_data[sample_idx, :, feat_idx], \n",
    "                   label=f'F{feat_idx + 1}', alpha=0.8, linewidth=2,\n",
    "                   color=feature_colors[feat_idx])\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(x_axis, y_data[sample_idx, :], color='#555555', linestyle='--', label='Target', \n",
    "                alpha=0.9, linewidth=2.5)\n",
    "        ax2.set_ylabel('Target', color='#555555', fontsize=11)\n",
    "        ax.legend(loc='upper left', fontsize=9)\n",
    "        ax2.legend(loc='upper right', fontsize=9)\n",
    "        ax.set_xlabel('Sequence Position', fontsize=11)\n",
    "        ax.set_ylabel('Feature Values', fontsize=11)\n",
    "    ax.set_title(f'Sample {sample_idx + 1} Evolution', fontsize=11, pad=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "def _print_regression_statistics(X_data, y_data, num_features, batch_size):\n",
    "    \"\"\"Print regression stats.\"\"\"\n",
    "    print(f\"Features: {num_features}, Samples: {batch_size}\")\n",
    "    print(f\"Sequence length: {X_data.shape[1]}\")\n",
    "    print(f\"Feature stats:\")\n",
    "    for feat_idx in range(num_features):\n",
    "        feat_data = X_data[:, :, feat_idx].flatten()\n",
    "        print(f\"  Feature {feat_idx + 1}: mean={feat_data.mean():.3f}, std={feat_data.std():.3f}, range=[{feat_data.min():.3f}, {feat_data.max():.3f}]\")\n",
    "    target_data = y_data.flatten()\n",
    "    print(f\"Target: mean={target_data.mean():.3f}, std={target_data.std():.3f}, range=[{target_data.min():.3f}, {target_data.max():.3f}]\")\n",
    "    print(f\"Feature-Target correlations:\")\n",
    "    for feat_idx in range(num_features):\n",
    "        feat_data = X_data[:, :, feat_idx].flatten()\n",
    "        correlation = np.corrcoef(feat_data, target_data)[0, 1]\n",
    "        print(f\"  Feature {feat_idx + 1} <-> Target: {correlation:.3f}\")\n",
    "\n",
    "def plot_classification_samples(X_data, y_data, title, batch_size=4, max_classes=5):\n",
    "    \"\"\"Plot 3D classification samples.\"\"\"\n",
    "    colors = ['#e41a1c', '#377eb8', '#4daf4a', '#ff7f00', '#984ea3']\n",
    "    marker = 'o'\n",
    "    rows, cols = 2, 2\n",
    "    all_classes = np.unique(y_data.flatten())\n",
    "    global_class_counts = {cls: np.sum(y_data == cls) for cls in all_classes}\n",
    "    print(\"Class distribution:\")\n",
    "    for cls, count in global_class_counts.items():\n",
    "        percentage = count / y_data.size * 100\n",
    "        print(f\"  Class {cls}: {count} points ({percentage:.1f}%)\")\n",
    "    fig = plt.figure(figsize=(16, 14))\n",
    "    axes = []\n",
    "    for i in range(rows * cols):\n",
    "        ax = fig.add_subplot(rows, cols, i + 1, projection='3d')\n",
    "        axes.append(ax)\n",
    "    for i in range(batch_size):\n",
    "        X_i = X_data[i, :, :3]\n",
    "        y_i = y_data[i, :].astype(int)\n",
    "        unique_classes, class_counts = np.unique(y_i, return_counts=True)\n",
    "        ax = axes[i]\n",
    "        for j, class_idx in enumerate(unique_classes):\n",
    "            mask = (y_i == class_idx)\n",
    "            if np.any(mask):\n",
    "                color = colors[class_idx % len(colors)]\n",
    "                ax.scatter(X_i[mask, 0], X_i[mask, 1], X_i[mask, 2],\n",
    "                           color=color, alpha=0.85, s=80, marker=marker,\n",
    "                           label=f'C{class_idx} ({class_counts[j]}pts)')\n",
    "                centroid = np.mean(X_i[mask, :3], axis=0)\n",
    "                ax.scatter(centroid[0], centroid[1], centroid[2],\n",
    "                           color=color, s=120, marker='X', alpha=1.0, linewidths=1)\n",
    "        dominant_class = unique_classes[np.argmax(class_counts)]\n",
    "        class_diversity = len(unique_classes)\n",
    "        ax.set_title(f\"Sample {i + 1}\\n{class_diversity} classes, Dom: C{dominant_class}\", fontsize=13)\n",
    "        ax.set_xlabel(\"Feature 1\", fontsize=11)\n",
    "        ax.set_ylabel(\"Feature 2\", fontsize=11)\n",
    "        ax.set_zlabel(\"Feature 3\", fontsize=11)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(fontsize=10, loc='upper right')\n",
    "    for i in range(batch_size, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    total_samples = batch_size\n",
    "    avg_classes_per_sample = np.mean([len(np.unique(y_data[i, :])) for i in range(batch_size)])\n",
    "    enhanced_title = f\"{title}\\n{total_samples} samples, Avg {avg_classes_per_sample:.1f} classes/sample, {len(all_classes)} unique classes overall\"\n",
    "    plt.suptitle(enhanced_title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_and_print_info(loader_or_path, loader_type=\"dump\"):\n",
    "    \"\"\"Load data and print info.\"\"\"\n",
    "    if loader_type == \"dump\":\n",
    "        if isinstance(loader_or_path, str):\n",
    "            loader = PriorDumpDataLoader(filename=loader_or_path, num_steps=1, batch_size=20, device='cpu')\n",
    "        else:\n",
    "            loader = loader_or_path\n",
    "    else:\n",
    "        loader = loader_or_path\n",
    "    batch = next(iter(loader))\n",
    "    X_data = batch[\"x\"].cpu().numpy()\n",
    "    y_data = batch[\"y\"].cpu().numpy()\n",
    "    print(f\"Data shape: X={X_data.shape}, y={y_data.shape}\")\n",
    "    print(f\"Single eval pos: {batch['single_eval_pos']}\")\n",
    "    return X_data, y_data, batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2436bf",
   "metadata": {},
   "source": [
    "## 1. TICL MLP Prior for Regression\n",
    "\n",
    "This section loads regression data generated from MLP (Multi-Layer Perceptron) priors. The plots show:\n",
    "- How each feature relates to the target variable\n",
    "- How data patterns evolve across a sequence for multiple samples\n",
    "- Statistical relationships between features and the target\n",
    "\n",
    "You can create the data file for this section with:\n",
    "```bash\n",
    "python -m tabularpriors --lib ticl --prior_type mlp --num_batches 1 --batch_size 4 --max_features 3 --max_seq_len 25\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3605956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize TICL MLP prior data from dump\n",
    "path_to_dump = \"prior_ticl_mlp_1x4_25x3.h5\"\n",
    "\n",
    "# Load data and print information\n",
    "X_all, y_all, batch = load_and_print_info(path_to_dump, \"dump\")\n",
    "\n",
    "# Visualize the regression data\n",
    "plot_regression_samples(\n",
    "    X_data=X_all, \n",
    "    y_data=y_all, \n",
    "    title=\"TICL MLP Prior Samples from Dump (Regression)\", \n",
    "    color=\"blue\", \n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a73f18",
   "metadata": {},
   "source": [
    "## 2. TICL GP Prior for Regression\n",
    "\n",
    "This section loads regression data generated from Gaussian Process priors. The plots show:\n",
    "- How each feature relates to the target variable\n",
    "- How data patterns evolve across a sequence for multiple samples\n",
    "- Statistical relationships between features and the target\n",
    "\n",
    "You can create the data file for this section with:\n",
    "```bash\n",
    "python -m tabularpriors --lib ticl --prior_type gp --num_batches 1 --batch_size 4 --max_features 3 --max_seq_len 25\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c173821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize TICL GP prior data from dump\n",
    "path_to_gp_dump = \"prior_ticl_gp_1x4_25x3.h5\"\n",
    "\n",
    "# Load data and print information\n",
    "X_gp, y_gp, gp_batch = load_and_print_info(path_to_gp_dump, \"dump\")\n",
    "\n",
    "# Visualize the GP regression data\n",
    "plot_regression_samples(\n",
    "    X_data=X_gp, \n",
    "    y_data=y_gp, \n",
    "    title=\"TICL GP Prior Samples from Dump (Regression)\", \n",
    "    color=\"blue\", \n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3716c697",
   "metadata": {},
   "source": [
    "## 3. TabICL Prior for Classification\n",
    "\n",
    "This section loads classification data from TabICL priors. The visualizations show:\n",
    "- Class distributions in 3D feature space\n",
    "- Class centroids and boundaries \n",
    "- Distribution of points across different classes\n",
    "\n",
    "You can create the data file for this section with:\n",
    "```bash\n",
    "python -m tabularpriors --lib tabicl --num_batches 1 --batch_size 4 --max_features 3 --max_seq_len 25 --max_classes 5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize TabICL prior data from dump\n",
    "path_to_tabicl_dump = \"prior_tabicl_1x4_25x3.h5\"\n",
    "\n",
    "# Load data and print information\n",
    "X_tabicl_dump, y_tabicl_dump, tabicl_dump_batch = load_and_print_info(path_to_tabicl_dump, \"dump\")\n",
    "print(f\"TabICL unique classes: {np.unique(y_tabicl_dump)}\")\n",
    "\n",
    "# Visualize the classification data\n",
    "plot_classification_samples(\n",
    "    X_data=X_tabicl_dump, \n",
    "    y_data=y_tabicl_dump, \n",
    "    title=\"TabICL Prior Samples from Dump (Classification)\", \n",
    "    batch_size=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287e80e6",
   "metadata": {},
   "source": [
    "## 4. Live Data Generation (Real-time Synthesis)\n",
    "\n",
    "This section demonstrates generating synthetic data on-the-fly instead of loading from pre-generated files. \n",
    "This approach is useful for:\n",
    "- Experimenting with different prior configurations\n",
    "- Testing parameter sensitivity\n",
    "- Generating data with specific random seeds\n",
    "- Immediate visualization without creating intermediate files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed50bd",
   "metadata": {},
   "source": [
    "### 4.1 Live TICL MLP Regression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b516a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Live TICL MLP Loader (Real-time Generation)\n",
    "from tabularpriors.dataloader import TICLPriorDataLoader\n",
    "from tabularpriors.utils import build_ticl_prior\n",
    "import torch\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "print(\"=== Testing Live TICL MLP Loader ===\")\n",
    "# Create live TICL MLP loader\n",
    "ticl_mlp_loader = TICLPriorDataLoader(\n",
    "    prior=build_ticl_prior('mlp'),\n",
    "    num_steps=1,\n",
    "    batch_size=20,\n",
    "    num_datapoints_max=50,\n",
    "    num_features=1,\n",
    "    device=device,\n",
    "    min_eval_pos=10,\n",
    ")\n",
    "\n",
    "# Load data and print information\n",
    "X_ticl_mlp, y_ticl_mlp, ticl_batch = load_and_print_info(ticl_mlp_loader, \"live\")\n",
    "\n",
    "# Visualize the live MLP data\n",
    "plot_regression_samples(\n",
    "    X_data=X_ticl_mlp, \n",
    "    y_data=y_ticl_mlp, \n",
    "    title=\"Live TICL MLP Prior Samples (Real-time Regression)\", \n",
    "    color=\"green\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a668c5",
   "metadata": {},
   "source": [
    "### 4.2 Live TICL GP Regression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96fad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Live TICL GP Loader (Real-time Generation)\n",
    "print(\"=== Testing Live TICL GP Loader ===\")\n",
    "\n",
    "# Create live TICL GP loader\n",
    "ticl_gp_loader = TICLPriorDataLoader(\n",
    "    prior=build_ticl_prior('gp'),\n",
    "    num_steps=1,\n",
    "    batch_size=20,\n",
    "    num_datapoints_max=50,\n",
    "    num_features=1,\n",
    "    device=device,\n",
    "    min_eval_pos=10,\n",
    ")\n",
    "\n",
    "# Load data and print information\n",
    "X_ticl_gp, y_ticl_gp, ticl_gp_batch = load_and_print_info(ticl_gp_loader, \"live\")\n",
    "\n",
    "# Visualize the live GP data\n",
    "plot_regression_samples(\n",
    "    X_data=X_ticl_gp, \n",
    "    y_data=y_ticl_gp, \n",
    "    title=\"Live TICL GP Prior Samples (Real-time Regression)\", \n",
    "    color=\"darkgreen\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281c62d",
   "metadata": {},
   "source": [
    "### 4.3 Live TabICL Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f34c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Live TabICL Loader (Real-time Classification)\n",
    "from tabularpriors.dataloader import TabICLPriorDataLoader\n",
    "\n",
    "print(\"=== Testing Live TabICL Loader ===\")\n",
    "\n",
    "# Create live TabICL loader\n",
    "tabicl_live_loader = TabICLPriorDataLoader(\n",
    "    num_steps=1,\n",
    "    batch_size=20,\n",
    "    num_datapoints_max=50,\n",
    "    num_features=3,\n",
    "    max_num_classes=5,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Load data and print information\n",
    "X_tabicl_live, y_tabicl_live, tabicl_live_batch = load_and_print_info(tabicl_live_loader, \"live\")\n",
    "\n",
    "# Visualize the live classification data\n",
    "plot_classification_samples(\n",
    "    X_data=X_tabicl_live, \n",
    "    y_data=y_tabicl_live, \n",
    "    title=\"Live TabICL Prior Samples (Real-time Classification)\", \n",
    "    batch_size=4\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabularpriors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
